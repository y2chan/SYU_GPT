import google.generativeai as genai
import streamlit as st

st.set_page_config(
    page_title="SYU-GPT",
    page_icon="ğŸ˜ƒ",
    #page_icon="photo/Logo.png",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items={
        'Get Help': 'https://www.extremelycoolapp.com/help',
        'Report a bug': "https://www.extremelycoolapp.com/bug",
    }
)

#st.image("photo/image.png")
st.title('SYU-GPT', anchor=False)

# ë¨¼ì €, subheaderì™€ captionì„ í¬í•¨í•˜ëŠ” ë¶€ë¶„ì„ st.empty()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ˆ í™€ë”ë¡œ ë§Œë“­ë‹ˆë‹¤.
info_placeholder = st.empty()

# ì´ì œ info_placeholderë¥¼ ì‚¬ìš©í•˜ì—¬ subheaderì™€ captionì„ í‘œì‹œí•©ë‹ˆë‹¤.
with info_placeholder.container():
    st.subheader('ì‚¼ìœ¡ëŒ€í•™êµ ê²€ìƒ‰ ì—”ì§„')
    st.caption('ì—¬ëŸ¬ë¶„ì´ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í•™êµ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”!')
    st.caption('ë§¤ì¼ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤.')
    st.caption('ì‚¼ìœ¡ëŒ€í•™êµ ì¬í•™ìƒì´ë¼ë©´ ì‚¬ìš©í•´ë³´ì„¸ìš”! ğŸ˜Š')
    st.caption(' ')

# ì‚¬ì´ë“œë°”
st.sidebar.title("ëª©ë¡")
st.sidebar.write('-' * 50)
st.sidebar.page_link("testmain.py", label="í™ˆ", help="í™ˆ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤")
st.sidebar.page_link("pages/greeting.py", label="ì¸ì‚¬ë§")
st.sidebar.page_link("pages/guide.py", label="ì‚¬ìš© ê°€ì´ë“œ")

@st.cache_resource
def load_model():
    model = genai.GenerativeModel('gemini-pro')
    print("model loaded...")
    return model

model = load_model()

if "chat_session" not in st.session_state:
    st.session_state["chat_session"] = model.start_chat(history=[])

for content in st.session_state.chat_session.history:
    with st.chat_message("ai", avatar="ğŸ¤–" if content.role == "model" else "ğŸ§ƒ"):
        st.markdown(content.parts[0].text)

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    # ì‚¬ìš©ìê°€ ì…ë ¥ì„ ì‹œì‘í•˜ë©´, info_placeholderë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ìˆ¨ê¹ë‹ˆë‹¤.
    info_placeholder.empty()  # ì´ì œ subheaderì™€ captionì´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.

    # ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§
    with st.chat_message("user", avatar="ğŸ§ƒ"):
        st.markdown(prompt)
    with st.chat_message("ai", avatar="ğŸ¤–"):
        message_placeholder = st.empty() # DeltaGenerator ë°˜í™˜
        full_response = ""
        with st.spinner("ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            response = st.session_state.chat_session.send_message(prompt, stream=True)
            for chunk in response:
                full_response += chunk.text
                message_placeholder.markdown(full_response)