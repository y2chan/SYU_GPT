import streamlit as st
from streamlit_chat import message
import time
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import DirectoryLoader

def display_conversation():
    for role, prompt in st.session_state['conversation']:
        if role == "user":
            with st.chat_message(role, avatar="ğŸ§ƒ"):
                st.markdown(prompt)
        else:
            with st.chat_message(role, avatar="photo/Logo.png"):
                st.markdown(prompt)

def run_app():
    st.set_page_config(
        page_title="SYU-GPT",
        page_icon="photo/Logo.png",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            'Get Help': 'https://www.extremelycoolapp.com/help',
            'Report a bug': "https://www.extremelycoolapp.com/bug",
        }
    )

    # ì œëª©
    st.title('SYU-GPT', anchor=False)

    # ë¨¼ì €, subheaderì™€ captionì„ í¬í•¨í•˜ëŠ” ë¶€ë¶„ì„ st.empty()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ˆ í™€ë”ë¡œ ë§Œë“­ë‹ˆë‹¤.
    info_placeholder = st.empty()

    # ì´ì œ info_placeholderë¥¼ ì‚¬ìš©í•˜ì—¬ subheaderì™€ captionì„ í‘œì‹œí•©ë‹ˆë‹¤.
    with info_placeholder.container():
        st.subheader('ì‚¼ìœ¡ëŒ€í•™êµ ê²€ìƒ‰ ì—”ì§„', anchor=False)
        st.caption('ì—¬ëŸ¬ë¶„ì´ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í•™êµ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”!')
        st.caption('ë§¤ì¼ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤.')
        st.caption('ì‚¼ìœ¡ëŒ€í•™êµ ì¬í•™ìƒì´ë¼ë©´ ì‚¬ìš©í•´ë³´ì„¸ìš”! ğŸ˜Š')
        st.caption(' ')

    # ì‚¬ì´ë“œë°”
    st.sidebar.image("photo/syugptLogo.png")
    hide_img_fs = '''
    <style>
    button[title="View fullscreen"]{
        visibility: hidden;}
    </style>
    '''
    st.sidebar.markdown(hide_img_fs, unsafe_allow_html=True)

    st.sidebar.write('-' * 50)
    st.sidebar.subheader("Menu")
    st.sidebar.page_link("main.py", label="í™ˆ", help="í™ˆ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤")
    st.sidebar.page_link("pages/greeting.py", label="ì¸ì‚¬ë§")
    st.sidebar.page_link("pages/guide.py", label="ì‚¬ìš© ê°€ì´ë“œ")
    st.sidebar.subheader("Other Web")
    st.sidebar.page_link("https://chat.openai.com/", label="ChatGPT", help="Chat GPT ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤")
    st.sidebar.page_link("https://gabean.kr/", label="GaBean", help="ê°œë°œìì˜ ë˜ ë‹¤ë¥¸ ì›¹ ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤")

    if "chat_session" not in st.session_state:
        st.session_state["conversation"] = [] # ëŒ€í™” ì´ë ¥ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
        # ì‚¬ìš©ìê°€ ì…ë ¥ì„ ì‹œì‘í•˜ë©´, info_placeholderë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ìˆ¨ê¹ë‹ˆë‹¤.
        info_placeholder.empty()  # ì´ì œ subheaderì™€ captionì´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.

        # ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
        # ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ì¸ë±ì‹±í•©ë‹ˆë‹¤.

        loader = TextLoader("data/SYU_GPT data.txt")
        # loader = DirectoryLoader(".", glob="data/SYU_GPT/*.txt", show_progress=True)
        docs = loader.load()

        # ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)

        splits = text_splitter.split_documents(docs)

        # ë‹¨ê³„ 3: ì„ë² ë”© & ë²¡í„°ìŠ¤í† ì–´ ìƒì„±(Create Vectorstore)
        # ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())

        # ë‹¨ê³„ 4: ê²€ìƒ‰(Search)
        # ë‰´ìŠ¤ì— í¬í•¨ë˜ì–´ ìˆëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
        retriever = vectorstore.as_retriever()

        # ë‹¨ê³„ 5: í”„ë¡¬í”„íŠ¸ ìƒì„±(Create Prompt)
        # í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        prompt = hub.pull("rlm/rag-prompt")

        # ë‹¨ê³„ 6: ì–¸ì–´ëª¨ë¸ ìƒì„±(Create LLM)
        # ëª¨ë¸(LLM) ì„ ìƒì„±í•©ë‹ˆë‹¤.
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

        def format_docs(docs):
            # ê²€ìƒ‰í•œ ë¬¸ì„œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
            return "\n\n".join(doc.page_content for doc in docs)

        # ë‹¨ê³„ 7: ì²´ì¸ ìƒì„±(Create Chain)
        rag_chain = (
                {"context": retriever | format_docs, "question": RunnablePassthrough()}
                | prompt
                | llm
                | StrOutputParser()
        )

        # ë‹¨ê³„ 8: ì²´ì¸ ì‹¤í–‰(Run Chain)
        # ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ê³ , ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        question = user_input

        spinner = st.empty()

        with spinner.container():
            with st.spinner("ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                time.sleep(2)
                st.success("ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                time.sleep(2)

        with spinner.empty():
            response = rag_chain.invoke(question)

            # ëŒ€í™”ì— ì¶”ê°€
        st.session_state['conversation'].append(('user', user_input))
        st.session_state['conversation'].append(('SYU-GPT', response))

        # ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— ì¶œë ¥
        display_conversation()

        # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
        st.session_state['user_input'] = ""

        st.caption(" ")
        st.caption(" ")
        st.page_link("main.py", label="ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", help="ì²˜ìŒ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤")

# ì•± ì‹¤í–‰
run_app()
