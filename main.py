import os
import streamlit as st
from langchain import hub
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import DirectoryLoader

# í™˜ê²½ ì„¤ì •
def setup_environment():
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
    os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_TOKEN")
    os.environ["LANGCHAIN_PROJECT"] = "SYU-GPT"
    os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_TOKEN")
    os.environ["SERPER_API_KEY"] = os.getenv("SERPER_API_KEY")

# ë¬¸ì„œ ì²˜ë¦¬ ì¤€ë¹„
def prepare_documents():
    if "retrievers" not in st.session_state:
        st.session_state.retrievers = []  # retrievers ì´ˆê¸°í™”

    # íŒŒì¼ë³„ ì„¤ì •
    config = {
        'introduce.txt': {'chunk_size': 1500, 'chunk_overlap': 300},
        'ê´€ë ¨ ë§í¬ data.txt': {'chunk_size': 1000, 'chunk_overlap': 200},
        'êµí†µ data.txt': {'chunk_size': 1500, 'chunk_overlap': 300},
        'ë„ì„œê´€ data.txt': {'chunk_size': 2000, 'chunk_overlap': 300},
        'ë™ì•„ë¦¬ data.txt': {'chunk_size': 1500, 'chunk_overlap': 250},
        'ë“±ë¡ data.txt': {'chunk_size': 1500, 'chunk_overlap': 250},
        'ì„±ì  data.txt': {'chunk_size': 1500, 'chunk_overlap': 300},
        'ì…”í‹€ë²„ìŠ¤ data.txt': {'chunk_size': 2000, 'chunk_overlap': 300},
        'ìˆ˜ê°•ì‹ ì²­ data.txt': {'chunk_size': 1500, 'chunk_overlap': 250},
        'ì‹œì„¤ ì •ë³´ data.txt': {'chunk_size': 2000, 'chunk_overlap': 350},
        'ì—…ë¬´ë³„ ì „í™”ë²ˆí˜¸ data.txt': {'chunk_size': 1000, 'chunk_overlap': 200},
        'ì¥í•™ê¸ˆ data.txt': {'chunk_size': 1200, 'chunk_overlap': 250},
        'ì¡¸ì—… data.txt': {'chunk_size': 1200, 'chunk_overlap': 250},
        'ì¦ëª…ì„œ data.txt': {'chunk_size': 1200, 'chunk_overlap': 250},
        'í•™ê³¼ data.txt': {'chunk_size': 1200, 'chunk_overlap': 250},
        'í•™ì‚¬ ì¼ì • data.txt': {'chunk_size': 1500, 'chunk_overlap': 300},
        'í›„ë¬¸ ì •ë³´ data.txt': {'chunk_size': 1000, 'chunk_overlap': 200},
        'í•™êµ ê±´ë¬¼ data.txt': {'chunk_size': 2000, 'chunk_overlap': 300},
    }

    # DirectoryLoaderë¡œ ëª¨ë“  txt íŒŒì¼ ë¡œë“œ
    loader = DirectoryLoader(".", glob="data/SYU_GPT/*.txt", show_progress=True)
    docs = loader.load()

    for doc in docs:
        file_path = doc.metadata['source']
        file_name = os.path.basename(file_path)

        if file_name in config:
            chunk_size = config[file_name]['chunk_size']
            chunk_overlap = config[file_name]['chunk_overlap']
        else:
            chunk_size = 1500
            chunk_overlap = 300

        text_splitter = CharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separator="\n"
        )
        splits = text_splitter.split_documents([doc])

        if splits:
            vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())
            st.session_state.retrievers.append(vectorstore.as_retriever())
        else:
            print(f"No splits found for {file_name}. Skipping.")

# ì‘ë‹µ ìƒì„±
def generate_response(user_input):
    try:
        # ì„¸ì…˜ ìƒíƒœì—ì„œ retrievers ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸
        if "retrievers" not in st.session_state or not st.session_state.retrievers:
            return "ë¬¸ì„œ ì²˜ë¦¬ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì£¼ì„¸ìš”."

        # ë¬¸ì„œ ì²˜ë¦¬ê¸°(retriever)ë¥¼ ì„ íƒ
        retriever = st.session_state.retrievers[0]  # ì˜ˆì œì—ì„œëŠ” ì²« ë²ˆì§¸ retrieverë¥¼ ì‚¬ìš©

        # LangChainì˜ RAG êµ¬ì„±ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        prompt = hub.pull("rlm/rag-prompt")
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, max_tokens=300)

        # ë¬¸ì„œ í˜•ì‹ì„ ì •ì˜
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        # RAG ì²´ì¸ êµ¬ì„±
        rag_chain = (
                {"context": retriever | format_docs, "question": RunnablePassthrough()}  # context íŒŒì´í”„ë¼ì¸ ìˆ˜ì •
                | prompt
                | llm
                | StrOutputParser()
        )

        # ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ ë°˜í™˜
        response = rag_chain.invoke(user_input)
        return response
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ëŠ” ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."



# ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ê°•í™”í•˜ì—¬ API ê¶Œí•œ ë¬¸ì œì— ëŒ€í•´ ì¢€ ë” ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µ
def main():
    st.set_page_config(page_title="SYU-GPT", layout="wide", initial_sidebar_state="expanded", menu_items={'Get Help': 'https://www.extremelycoolapp.com/help', 'Report a bug': "https://www.extremelycoolapp.com/bug",})

    st.title('SYU-GPT', anchor=False)

    # ë¨¼ì €, subheaderì™€ captionì„ í¬í•¨í•˜ëŠ” ë¶€ë¶„ì„ st.empty()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ˆ í™€ë”ë¡œ ë§Œë“­ë‹ˆë‹¤.
    info_placeholder = st.empty()

    # ì´ì œ info_placeholderë¥¼ ì‚¬ìš©í•˜ì—¬ subheaderì™€ captionì„ í‘œì‹œí•©ë‹ˆë‹¤.
    with info_placeholder.container():
        st.subheader('ì‚¼ìœ¡ëŒ€í•™êµ ê²€ìƒ‰ ì—”ì§„', anchor=False)
        st.caption('ì—¬ëŸ¬ë¶„ì´ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í•™êµ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”!')
        st.caption('ë§¤ì¼ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤.')
        st.caption('ì‚¼ìœ¡ëŒ€í•™êµ ì¬í•™ìƒì´ë¼ë©´ ì‚¬ìš©í•´ë³´ì„¸ìš”! ğŸ˜Š')
        st.caption(' ')

    # ì‚¬ì´ë“œë°”
    st.sidebar.image("photo/syugptLogo.png")
    hide_img_fs = '''
    <style>
    button[title="View fullscreen"]{
        visibility: hidden;}
    </style>
    '''
    st.sidebar.markdown(hide_img_fs, unsafe_allow_html=True)

    st.sidebar.write('-' * 50)
    st.sidebar.subheader("Menu")
    st.sidebar.page_link("main.py", label="í™ˆ", help="í™ˆ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤")
    st.sidebar.page_link("pages/greeting.py", label="ì¸ì‚¬ë§")
    st.sidebar.page_link("pages/guide.py", label="ì‚¬ìš© ê°€ì´ë“œ")
    st.sidebar.subheader("Other Web")
    st.sidebar.page_link("https://chat.openai.com/", label="ChatGPT", help="Chat GPT ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤")
    st.sidebar.page_link("https://gabean.kr/", label="GaBean", help="ê°œë°œìì˜ ë˜ ë‹¤ë¥¸ ì›¹ ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤")

    if "chat_session" not in st.session_state:
        st.session_state.messages = []

    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
        info_placeholder.empty()
        setup_environment()
        try:
            prepare_documents()
            # ê¸°íƒ€ ì½”ë“œ êµ¬í˜„
        except Exception as e:
            st.error(f"An unexpected error occurred: {e}")

        try:
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                response = generate_response(user_input)

            with st.chat_message("user", avatar="ğŸ§ƒ"):
                st.markdown(user_input)
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.chat_message("SYU-GPT", avatar="photo/Logo.png"):
                st.markdown(response)
            st.session_state.messages.append({"role": "SYU-GPT", "content": response})
        except Exception as e:
            st.error("ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {}".format(e))

if __name__ == "__main__":
    main()